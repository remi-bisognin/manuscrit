\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Bayesian approach for deconvolution in electronic tomography }{85}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec: Bayesian approach for deconvolution in electronic tomography}{{A}{85}{Bayesian approach for deconvolution in electronic tomography}{appendix.A}{}}
\newlabel{sec: The deconvolution problem}{{A.1}{85}{\texorpdfstring {The deconvolution problem}{The deconvolution problem}\label {sec: The deconvolution problem}}{section.A.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}The deconvolution problem}{85}{section.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}The deconvolution in our specific case}{85}{subsection.A.1.1}\protected@file@percent }
\MT@newlabel{eq: convolution spectro}
\MT@newlabel{eq: convolution real part tomo}
\MT@newlabel{eq: convolution imag part tomo}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces \textbf  {Schematic representation of the direct model.} The measured excess noise is modelled as the convolution by a probe function plus some additional noise $N$. In this case we replace the convolution product by its equivalent matrix product $H$. The issue of this annex is to propose what can replace the question marks, and recover $\Delta W_{S}$ from $\Delta S$.\relax }}{85}{figure.caption.58}\protected@file@percent }
\newlabel{fig: direct model}{{A.1}{85}{\textbf {Schematic representation of the direct model.} The measured excess noise is modelled as the convolution by a probe function plus some additional noise $N$. In this case we replace the convolution product by its equivalent matrix product $H$. The issue of this annex is to propose what can replace the question marks, and recover $\Delta W_{S}$ from $\Delta S$.\relax }{figure.caption.58}{}}
\MT@newlabel{eq: direct model}
\newlabel{eq: direct model}{{A.1}{85}{\texorpdfstring {The deconvolution in our specific case}{The deconvolution in our specific case}}{equation.A.1.1}{}}
\MT@newlabel{eq: direct model}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Why do we need a deconvolution method?}{86}{subsection.A.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces \textbf  {Theoretical calculations on 2GHz sine example at a temperature of 60mK.} \textbf  {(a)} left - Calculated theoretical noise $\Delta S_{\mathrm  {th}}$ - right - Calculated theoretical spectroscopy $\Delta W_{\mathrm  {th}}$. \textbf  {(b)} The whole calculated theoretical Wigner function.\relax }}{86}{figure.caption.59}\protected@file@percent }
\newlabel{fig: Theory}{{A.2}{86}{\textbf {Theoretical calculations on 2GHz sine example at a temperature of 60mK.} \textbf {(a)} left - Calculated theoretical noise $\Delta S_{\mathrm {th}}$ - right - Calculated theoretical spectroscopy $\Delta W_{\mathrm {th}}$. \textbf {(b)} The whole calculated theoretical Wigner function.\relax }{figure.caption.59}{}}
\citation{wiener1949extrapolation}
\MT@newlabel{eq: Pauli exclusion principle}
\newlabel{eq: Pauli exclusion principle}{{A.2}{87}{\texorpdfstring {Why do we need a deconvolution method?}{Why we need a deconvolution method?}}{equation.A.1.2}{}}
\newlabel{sec: Wiener filter}{{A.2}{87}{\texorpdfstring {The Fourier space technique: Wiener filter}{The Fourier space technique: Wiener filter}\label {sec: Wiener filter}}{section.A.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}The Fourier space technique: Wiener filter}{87}{section.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}The optimal Wiener filter in ideal case}{87}{subsection.A.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{wiener1949extrapolation}{{87}{A.2.1}{subsection.A.2.1}}}
\MT@newlabel{eq: Wiener criterion}
\newlabel{eq: Wiener criterion}{{A.3}{87}{\texorpdfstring {The optimal Wiener filter in ideal case}{The optimal Wiener filter in ideal case}}{equation.A.2.3}{}}
\MT@newlabel{eq: Wiener developpement}
\newlabel{eq: Wiener developpement}{{A.4}{87}{\texorpdfstring {The optimal Wiener filter in ideal case}{The optimal Wiener filter in ideal case}}{equation.A.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces \textbf  {Naive deconvolution method.} \textbf  {(a)} Schematic of the naive inverse technique which just consists in multiplying experimental data by the inverse matrix $H^{-1}$. \textbf  {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm  {th}}$ and re-convoluted solution $H\Delta W$, all take similar values - right - Solution of the naive deconvolution $\Delta W$ which is order of magnitude greater than the theoretical solution $\Delta W_{\mathrm  {th}}$. \textbf  {(c)} left - Two measured data set $\Delta S$ and $\Delta S^{\prime }$ to which are added a random noise. These two data set take similar values. - right - Solution $\Delta W$ based on data points $\Delta S$, and solution $\Delta W^{\prime }$ based on data points $\Delta S^{\prime }$. These two solutions are very different even if the input data points are similar.\relax }}{88}{figure.caption.60}\protected@file@percent }
\newlabel{fig: naive deconvolution}{{A.3}{88}{\textbf {Naive deconvolution method.} \textbf {(a)} Schematic of the naive inverse technique which just consists in multiplying experimental data by the inverse matrix $H^{-1}$. \textbf {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm {th}}$ and re-convoluted solution $H\Delta W$, all take similar values - right - Solution of the naive deconvolution $\Delta W$ which is order of magnitude greater than the theoretical solution $\Delta W_{\mathrm {th}}$. \textbf {(c)} left - Two measured data set $\Delta S$ and $\Delta S^{\prime }$ to which are added a random noise. These two data set take similar values. - right - Solution $\Delta W$ based on data points $\Delta S$, and solution $\Delta W^{\prime }$ based on data points $\Delta S^{\prime }$. These two solutions are very different even if the input data points are similar.\relax }{figure.caption.60}{}}
\citation{wiener1949extrapolation}
\MT@newlabel{eq: optimal Wiener filter}
\newlabel{eq: optimal Wiener filter}{{A.5}{89}{\texorpdfstring {The optimal Wiener filter in ideal case}{The optimal Wiener filter in ideal case}}{equation.A.2.5}{}}
\@writefile{brf}{\backcite{wiener1949extrapolation}{{89}{A.2.1}{equation.A.2.5}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}The implemented Wiener filter}{89}{subsection.A.2.2}\protected@file@percent }
\MT@newlabel{eq: Wiener filter use for high SNR}
\newlabel{eq: Wiener filter use for high SNR}{{A.6}{89}{\texorpdfstring {The implemented Wiener filter}{The implemented Wiener filter}}{equation.A.2.6}{}}
\MT@newlabel{eq: Wiener filter use for low SNR}
\newlabel{eq: Wiener filter use for low SNR}{{A.7}{89}{\texorpdfstring {The implemented Wiener filter}{The implemented Wiener filter}}{equation.A.2.7}{}}
\MT@newlabel{eq: Wiener filter used}
\newlabel{eq: Wiener filter used}{{A.10}{89}{\texorpdfstring {The implemented Wiener filter}{The implemented Wiener filter}}{equation.A.2.8}{}}
\citation{marguerite2017extracting}
\citation{marguerite2017two}
\citation{ayasso2010joint}
\citation{mohammad2015bayesian}
\citation{zhao2016joint}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}The Bayesian framework}{90}{section.A.3}\protected@file@percent }
\@writefile{brf}{\backcite{marguerite2017extracting}{{90}{A.3}{section.A.3}}}
\@writefile{brf}{\backcite{marguerite2017two}{{90}{A.3}{section.A.3}}}
\@writefile{brf}{\backcite{ayasso2010joint}{{90}{A.3}{section.A.3}}}
\@writefile{brf}{\backcite{mohammad2015bayesian}{{90}{A.3}{section.A.3}}}
\@writefile{brf}{\backcite{zhao2016joint}{{90}{A.3}{section.A.3}}}
\MT@newlabel{eq: likelyhood}
\newlabel{eq: likelyhood}{{A.11}{90}{\texorpdfstring {The Bayesian framework}{The Bayesian framework}}{equation.A.3.11}{}}
\MT@newlabel{eq: Bayes'formula}
\newlabel{eq: Bayes'formula}{{A.12}{90}{\texorpdfstring {The Bayesian framework}{The Bayesian framework}}{equation.A.3.12}{}}
\MT@newlabel{eq: prior distribution annexe}
\newlabel{eq: prior distribution annexe}{{A.13}{90}{\texorpdfstring {The Bayesian framework}{The Bayesian framework}}{equation.A.3.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces \textbf  {Wiener deconvolution filter.} \textbf  {(a)} Schematic of Wiener deconvolution technique, the inversion $H^{-1}$ and the filtering $F$ are performed in Fourier space since it is then reduced to a simple product. Indeed in the Fourier basis $H$ is diagonal. \textbf  {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm  {th}}$ and re-convoluted solution $H\Delta W$, all take similar values - right - Solution of the Wiener deconvolution $\Delta W$ which is consistent with expected calculations $\Delta W_{\mathrm  {th}}$, except for some oscillations at high energies. \textbf  {(c)} The whole Wigner function deduced from measurements thanks to Wiener deconvolution.\relax }}{91}{figure.caption.61}\protected@file@percent }
\newlabel{fig: Wiener_results}{{A.4}{91}{\textbf {Wiener deconvolution filter.} \textbf {(a)} Schematic of Wiener deconvolution technique, the inversion $H^{-1}$ and the filtering $F$ are performed in Fourier space since it is then reduced to a simple product. Indeed in the Fourier basis $H$ is diagonal. \textbf {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm {th}}$ and re-convoluted solution $H\Delta W$, all take similar values - right - Solution of the Wiener deconvolution $\Delta W$ which is consistent with expected calculations $\Delta W_{\mathrm {th}}$, except for some oscillations at high energies. \textbf {(c)} The whole Wigner function deduced from measurements thanks to Wiener deconvolution.\relax }{figure.caption.61}{}}
\citation{fessler1996mean}
\citation{pereyra2017maximum}
\citation{bardsley2012mcmc}
\citation{howard2014sampling}
\citation{fessler1996mean}
\MT@newlabel{eq:variances Vf}
\newlabel{eq:variances Vf}{{A.14}{92}{\texorpdfstring {The Bayesian framework}{The Bayesian framework}}{equation.A.3.14}{}}
\newlabel{sec: MAP}{{A.3.1}{92}{\texorpdfstring {Posterior law maximization}{Posterior law maximization}\label {sec: MAP}}{subsection.A.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Posterior law maximization}{92}{subsection.A.3.1}\protected@file@percent }
\MT@newlabel{eq: MAP criterion}
\newlabel{eq: MAP criterion}{{A.15}{92}{\texorpdfstring {Posterior law maximization}{Posterior law maximization}\label {sec: MAP}}{equation.A.3.15}{}}
\MT@newlabel{eq: MAP equation}
\@writefile{brf}{\backcite{fessler1996mean}{{92}{A.3.1}{equation.A.3.15}}}
\@writefile{brf}{\backcite{pereyra2017maximum}{{92}{A.3.1}{equation.A.3.15}}}
\newlabel{eq: MAP equation}{{A.16}{92}{\texorpdfstring {Posterior law maximization}{Posterior law maximization}\label {sec: MAP}}{equation.A.3.16}{}}
\@writefile{brf}{\backcite{bardsley2012mcmc}{{92}{A.3.1}{figure.caption.62}}}
\@writefile{brf}{\backcite{howard2014sampling}{{92}{A.3.1}{figure.caption.62}}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces \textbf  {Maximum A Posteriori deconvolution.} \textbf  {(a)} Schematic of MAP deconvolution, the inversion is performed by one matrix product $F$ in the direct space. Some a priori information $V_{f}$ is added to compute the matrix $F$. \textbf  {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm  {th}}$ and re-convoluted solution $H\Delta W$. - right - Solution of the MAP deconvolution $\Delta W$, as expected from $\Delta W_{th}$ the high energy oscillations are suppressed. \textbf  {(c)} The whole Wigner function deduced from measurements thanks to MAP. Yellow and blue spots at energies above 50 $\mu $eV are removed.\relax }}{93}{figure.caption.62}\protected@file@percent }
\newlabel{fig: MAP deconvolution}{{A.5}{93}{\textbf {Maximum A Posteriori deconvolution.} \textbf {(a)} Schematic of MAP deconvolution, the inversion is performed by one matrix product $F$ in the direct space. Some a priori information $V_{f}$ is added to compute the matrix $F$. \textbf {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm {th}}$ and re-convoluted solution $H\Delta W$. - right - Solution of the MAP deconvolution $\Delta W$, as expected from $\Delta W_{th}$ the high energy oscillations are suppressed. \textbf {(c)} The whole Wigner function deduced from measurements thanks to MAP. Yellow and blue spots at energies above 50 $\mu $eV are removed.\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces \textbf  {Random draws following the posterior distribution.} \textbf  {(a)} Solution deduce from the mean of random draws on the posterior distribution. We found the same result as for the maximum a posteriori. \textbf  {(b)} Each line along the x-axis is an histogram of solution $\Delta W\left (E\right )$ values for one energy $E$. Values on the z-axis are computed from the percentage of value $\Delta W\left (E\right )$ among the random draws.\relax }}{94}{figure.caption.63}\protected@file@percent }
\newlabel{fig: PM_for_MAP}{{A.6}{94}{\textbf {Random draws following the posterior distribution.} \textbf {(a)} Solution deduce from the mean of random draws on the posterior distribution. We found the same result as for the maximum a posteriori. \textbf {(b)} Each line along the x-axis is an histogram of solution $\Delta W\left (E\right )$ values for one energy $E$. Values on the z-axis are computed from the percentage of value $\Delta W\left (E\right )$ among the random draws.\relax }{figure.caption.63}{}}
\citation{mohammad2015bayesian}
\citation{ayasso2010joint}
\citation{zhao2016joint}
\MT@newlabel{eq: MAP covariance}
\MT@newlabel{eq: MAP equation}
\@writefile{brf}{\backcite{fessler1996mean}{{95}{A.3.1}{figure.caption.63}}}
\newlabel{eq: MAP covariance}{{A.17}{95}{\texorpdfstring {Posterior law maximization}{Posterior law maximization}\label {sec: MAP}}{equation.A.3.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.7}{\ignorespaces \textbf  {Covariance matrix of Maximum a posteriori solution.} left - covariance matrix estimated for random draws of input data $\Delta S$ plus a drawn noise $N$ - right - covariance matrix estimated by analytical calculation. These two methods show the same results.\relax }}{95}{figure.caption.64}\protected@file@percent }
\newlabel{fig: MAP_covariance}{{A.7}{95}{\textbf {Covariance matrix of Maximum a posteriori solution.} left - covariance matrix estimated for random draws of input data $\Delta S$ plus a drawn noise $N$ - right - covariance matrix estimated by analytical calculation. These two methods show the same results.\relax }{figure.caption.64}{}}
\newlabel{sec: JMAP}{{A.3.2}{95}{\texorpdfstring {Unsupervised technique with joint posterior law maximization}{Unsupervised technique with joint posterior law maximization}\label {sec: JMAP}}{subsection.A.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}Unsupervised technique with joint posterior law maximization}{95}{subsection.A.3.2}\protected@file@percent }
\MT@newlabel{eq: hyper-priors inverse gamma law}
\newlabel{eq: hyper-priors inverse gamma law}{{A.18}{95}{\texorpdfstring {Unsupervised technique with joint posterior law maximization}{Unsupervised technique with joint posterior law maximization}\label {sec: JMAP}}{equation.A.3.18}{}}
\MT@newlabel{eq: JMAP posterior law}
\newlabel{eq: JMAP posterior law}{{A.19}{95}{\texorpdfstring {Unsupervised technique with joint posterior law maximization}{Unsupervised technique with joint posterior law maximization}\label {sec: JMAP}}{equation.A.3.19}{}}
\@writefile{brf}{\backcite{mohammad2015bayesian}{{95}{A.3.2}{equation.A.3.19}}}
\@writefile{brf}{\backcite{ayasso2010joint}{{95}{A.3.2}{equation.A.3.19}}}
\@writefile{brf}{\backcite{zhao2016joint}{{95}{A.3.2}{equation.A.3.19}}}
\citation{ferraro2013wigner}
\citation{afonso2011augmented}
\citation{lanteri2002penalized}
\citation{chan2012multiplicative}
\citation{bardsley2012mcmc2}
\citation{figueiredo2007gradient}
\citation{bertsekas1997nonlinear}
\citation{marguerite2017two}
\MT@newlabel{eq: MAP equation}
\MT@newlabel{eq: Vf updates formula}
\newlabel{eq: Vf updates formula}{{A.20}{96}{\texorpdfstring {Unsupervised technique with joint posterior law maximization}{Unsupervised technique with joint posterior law maximization}\label {sec: JMAP}}{equation.A.3.20}{}}
\MT@newlabel{eq: prior distribution}
\MT@newlabel{eq: prior distribution}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.3}Box constrained problem with projected gradiant}{96}{subsection.A.3.3}\protected@file@percent }
\@writefile{brf}{\backcite{ferraro2013wigner}{{96}{A.3.3}{subsection.A.3.3}}}
\MT@newlabel{eq: Pauli exclusion principle}
\@writefile{brf}{\backcite{afonso2011augmented}{{96}{A.3.3}{subsection.A.3.3}}}
\@writefile{brf}{\backcite{lanteri2002penalized}{{96}{A.3.3}{subsection.A.3.3}}}
\@writefile{brf}{\backcite{chan2012multiplicative}{{96}{A.3.3}{subsection.A.3.3}}}
\@writefile{brf}{\backcite{bardsley2012mcmc2}{{96}{A.3.3}{subsection.A.3.3}}}
\@writefile{brf}{\backcite{figueiredo2007gradient}{{96}{A.3.3}{subsection.A.3.3}}}
\@writefile{brf}{\backcite{bertsekas1997nonlinear}{{96}{A.3.3}{subsection.A.3.3}}}
\MT@newlabel{eq: MAP equation}
\MT@newlabel{eq: solution projection inside box}
\newlabel{eq: solution projection inside box}{{A.21}{96}{\texorpdfstring {Box constrained problem with projected gradiant}{Box-constraint problem with projected gradiant}}{equation.A.3.21}{}}
\MT@newlabel{eq: MAP criterion}
\MT@newlabel{eq: gradient}
\newlabel{eq: gradient}{{A.22}{96}{\texorpdfstring {Box constrained problem with projected gradiant}{Box-constraint problem with projected gradiant}}{equation.A.3.22}{}}
\MT@newlabel{eq: gradient}
\MT@newlabel{eq: Vf updates formula}
\@writefile{lof}{\contentsline {figure}{\numberline {A.8}{\ignorespaces \textbf  {Joint Maximum A Posteriori deconvolution.} \textbf  {(a)} Schematic of JMAP deconvolution, the inversion is performed by one matrix product $F$ in the direct space. The solution is used to optimize the values of $V_{f}$ parameters, which follow an Inverse-Gamma law of shape parameter $\alpha $ and scale parameter $\beta $. After several loop step between $F$ and $V_{f}$ we get the solution $F\Delta S$. \textbf  {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm  {th}}$ and re-convoluted solution $H\Delta W$. - right - Solution of the JMAP deconvolution $\Delta W$, which is similar to the solution given by the MAP method. \textbf  {(c)} The whole Wigner function deduced from measurements thanks to JMAP.\relax }}{97}{figure.caption.65}\protected@file@percent }
\newlabel{fig: JMAP deconvolution}{{A.8}{97}{\textbf {Joint Maximum A Posteriori deconvolution.} \textbf {(a)} Schematic of JMAP deconvolution, the inversion is performed by one matrix product $F$ in the direct space. The solution is used to optimize the values of $V_{f}$ parameters, which follow an Inverse-Gamma law of shape parameter $\alpha $ and scale parameter $\beta $. After several loop step between $F$ and $V_{f}$ we get the solution $F\Delta S$. \textbf {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm {th}}$ and re-convoluted solution $H\Delta W$. - right - Solution of the JMAP deconvolution $\Delta W$, which is similar to the solution given by the MAP method. \textbf {(c)} The whole Wigner function deduced from measurements thanks to JMAP.\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.9}{\ignorespaces \textbf  {Projected gradient descent schematic.} In red the box given by the Pauli exclusion principle. In blue the criterion given by the posterior distribution law. In green projection for the initial value and the gradient. In gold solution given by the algorithm, which is the lowest value of the criterion in the box given by the Pauli exclusion principle.\relax }}{98}{figure.caption.66}\protected@file@percent }
\newlabel{fig: ProjGrad descent}{{A.9}{98}{\textbf {Projected gradient descent schematic.} In red the box given by the Pauli exclusion principle. In blue the criterion given by the posterior distribution law. In green projection for the initial value and the gradient. In gold solution given by the algorithm, which is the lowest value of the criterion in the box given by the Pauli exclusion principle.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Outlook: toward a 2D treatment}{98}{section.A.4}\protected@file@percent }
\@writefile{brf}{\backcite{marguerite2017two}{{98}{A.4}{section.A.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.10}{\ignorespaces \textbf  {Projected Gradient deconvolution method.} \textbf  {(a)} Schematic of the deconvolution method, first a MAP deconvolution is performed. Its solution $F\Delta S$ is projected by $P$ in the box $M$. Than starting from this initial value, one projected gradient descent step and one update of $V_{f}$ values are repeated at each loop step \textbf  {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm  {th}}$ and re-convoluted solution $H\Delta W$. - right - Solution of the deconvolution $\Delta W$. \textbf  {(c)} The whole Wigner function deduced from measurements. Almost all unexpected yellow and cyan spots are erased even in the energy range below 50 $\mu $eV.\relax }}{99}{figure.caption.67}\protected@file@percent }
\newlabel{fig: ProjGrad deconvolution}{{A.10}{99}{\textbf {Projected Gradient deconvolution method.} \textbf {(a)} Schematic of the deconvolution method, first a MAP deconvolution is performed. Its solution $F\Delta S$ is projected by $P$ in the box $M$. Than starting from this initial value, one projected gradient descent step and one update of $V_{f}$ values are repeated at each loop step \textbf {(b)} left - Measured data $\Delta S$, calculated theoretical noise $\Delta S_{\mathrm {th}}$ and re-convoluted solution $H\Delta W$. - right - Solution of the deconvolution $\Delta W$. \textbf {(c)} The whole Wigner function deduced from measurements. Almost all unexpected yellow and cyan spots are erased even in the energy range below 50 $\mu $eV.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.11}{\ignorespaces \textbf  {From 1D to 2D deconvolution.} \textbf  {(a)} - succession of 1D Project Gradient deconvolution method used in this manuscript - \textbf  {(b)} - perspective of a 2D deconvolution method.\relax }}{100}{figure.caption.68}\protected@file@percent }
\newlabel{fig: 1D->2D deconvolution}{{A.11}{100}{\textbf {From 1D to 2D deconvolution.} \textbf {(a)} - succession of 1D Project Gradient deconvolution method used in this manuscript - \textbf {(b)} - perspective of a 2D deconvolution method.\relax }{figure.caption.68}{}}
\@setckpt{appA}{
\setcounter{page}{101}
\setcounter{equation}{22}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{0}
\setcounter{FBcaption@count}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALC@unique}{28}
\setcounter{ALC@line}{28}
\setcounter{ALC@rem}{28}
\setcounter{ALC@depth}{0}
\setcounter{caption@flags}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{52}
\setcounter{section@level}{0}
}
